{
 "metadata": {
  "name": "",
  "signature": "sha256:0b04139e10af524e938789dc3f09c62e8d8684096d96b79d035954720e2e2707"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Introduction to OpenCL\n",
      "===\n",
      "\n",
      "This introduction is based on following article: <br>\n",
      "http://www.drdobbs.com/parallel/a-gentle-introduction-to-opencl/231002854\n",
      "\n",
      "In this introduction, we use a game analogy.<br>\n",
      "![Card Game v.s OpenCL](https://raw.githubusercontent.com/dboyliao/PyOpenCL_learn/master/fig/Scarpino1.gif)\n",
      "\n",
      "<font size='3'>\n",
      "- Device: OpenCL <font color='grass'>devices</font> correspond to the <font color='grass'>players</font>. Just as a player receives cards from the dealer, a device receives kernels from the host. In code, a device is represented by a <font color=\"red\">cl_device_id</font>.\n",
      "</font><br>\n",
      "\n",
      "<font size='3'>\n",
      "- Kernel: OpenCL <font color='grass'>kernels</font> correspond to the <font color=\"grass\">cards</font>. A host application distributes kernels to devices in much the same way a dealer distributes cards to players. In code, a kernel is represented by a <font color=\"red\">cl_kernel</font>.\n",
      "</font><br>\n",
      "\n",
      "<font size='3'>\n",
      "- Program: An OpenCL <font color=\"grass\">program</font> is like a <font color=\"grass\">deck of cards</font>. In the same way that a dealer selects cards from a deck, the host selects kernels from a program. In code, a program is represented by a <font color=\"red\">cl_program</font>.\n",
      "</font><br>\n",
      "\n",
      "<font size='3'>\n",
      "- Command queue: An OpenCL <font color=\"grass\">command queue</font> is like a <font color=\"grass\">player's hand</font>. Each player receives cards as part of a hand, and each device receives kernels through a command queue. In code, a command queue is represented by a <font color=\"red\">cl_command_queue</font>.\n",
      "</font><br>\n",
      "\n",
      "<font size='3'>\n",
      "- Context: OpenCL <font color=\"grass\">contexts</font> correspond to <font color=\"grass\">card tables</font>. Just as a card table makes it possible for players to transfer cards to one another, an OpenCL context allows devices to receive kernels and transfer data. In code, a context is represented by a <font color=\"red\">cl_context</font>.\n",
      "</font><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Important Cautions:\n",
      "\n",
      "There are few things that are missing in this analogy:\n",
      "\n",
      "- <font size='3'>Platform: A platform is a data structure that identifies a vendor's implementation of OpenCL. Platforms make it possible to access devices. For example, you can access an Nvidia device through the Nvidia platform.</font>\n",
      "- <font size='3'> A card dealer doesn't choose which players sit at the table. However, an OpenCL host selects which devices should be placed in a context. </font>\n",
      "- <font size='3'>A card dealer can't deal the same card to multiple players, but an OpenCL host can dispatch the same kernel to multiple devices through their command queues.</font>\n",
      "- <font size='3'>The analogy doesn't mention how devices execute kernels. Many OpenCL devices contain multiple processing elements, and each element may process a subset of the input data. The host identifies the number of work items that should be generated to execute the kernel.</font>\n",
      "- <font size='3'>In a card game, the dealer distributes cards to players and each player arranges the cards to form a hand. In OpenCL, the host creates a command queue for each device and enqueues commands. One type of command tells a device to execute a kernel.</font>\n",
      "- <font size='3'>In a card game, the dealer passes cards in a round-robin fashion. OpenCL sets no constraints on how host applications distribute kernels to devices.</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# PyOpenCL\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as cl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cl.get_platforms() will return a list of pyopencl.Platform instance which contain all information you may\n",
      "# need. See platforms and platform below for example.\n",
      "platforms = cl.get_platforms()\n",
      "print type(platforms)\n",
      "for platform in platforms:\n",
      "    print type(platform), platform"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'>\n",
        "<class 'pyopencl._cl.Platform'> <pyopencl.Platform 'Apple' at 0x7fff0000>\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Properties of a pyopencl.Platform instance has.\n",
      "platform = platforms[0]\n",
      "\n",
      "print \".extensions property is a string which list all extensions supported by the platform.\"\n",
      "print type(platform.extensions), platform.extensions\n",
      "\n",
      "print\n",
      "\n",
      "print \".name property is a string of platform's name\"\n",
      "print type(platform.name), platform.name\n",
      "\n",
      "print \n",
      "\n",
      "print \".profile is a string with two possible values.\"\n",
      "print \"1. FULL_PROFILE: the platform supports full OpenCL standard.\"\n",
      "print \"2. EMBEDDED_PROFILE: the platform supports only embedded OpenCL standard.\"\n",
      "print type(platform.profile), platform.profile\n",
      "\n",
      "print\n",
      "\n",
      "print \".vender property is a string with the platform's vendor name.\"\n",
      "print type(platform.vendor), platform.vendor\n",
      "\n",
      "print\n",
      "\n",
      "print \".version is a string with the maximum version of the OpenCL API supported by the platform.\"\n",
      "print type(platform.version), platform.version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".extensions property is a string which list all extensions supported by the platform.\n",
        "<type 'str'> cl_APPLE_SetMemObjectDestructor cl_APPLE_ContextLoggingFunctions cl_APPLE_clut cl_APPLE_query_kernel_names cl_APPLE_gl_sharing cl_khr_gl_event\n",
        "\n",
        ".name property is a string of platform's name\n",
        "<type 'str'> Apple\n",
        "\n",
        ".profile is a string with two possible values.\n",
        "1. FULL_PROFILE: the platform supports full OpenCL standard.\n",
        "2. EMBEDDED_PROFILE: the platform supports only embedded OpenCL standard.\n",
        "<type 'str'> FULL_PROFILE\n",
        "\n",
        ".vender property is a string with the platform's vendor name.\n",
        "<type 'str'> Apple\n",
        "\n",
        ".version is a string with the maximum version of the OpenCL API supported by the platform.\n",
        "<type 'str'> OpenCL 1.2 (Apr 25 2014 22:04:25)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"get_devices() return a list of pyopencl.Device instances.\"\n",
      "print \"By default, it is equivalent to get_devices(cl.device_type.ALL)\"\n",
      "print \n",
      "devices = platform.get_devices()\n",
      "print devices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get_devices() return a list of pyopencl.Device instances.\n",
        "By default, it is equivalent to get_devices(cl.device_type.ALL)\n",
        "\n",
        "[<pyopencl.Device 'Intel(R) Core(TM) i5-3210M CPU @ 2.50GHz' on 'Apple' at 0xffffffff>, <pyopencl.Device 'HD Graphics 4000' on 'Apple' at 0x1024400>]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Or you can choose to return only GPU(or CPU) devices.\"\n",
      "print \n",
      "gpu_devices = platform.get_devices(cl.device_type.GPU)\n",
      "print gpu_devices[0]\n",
      "print\n",
      "cpu_devices = platform.get_devices(cl.device_type.CPU)\n",
      "print cpu_devices[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Or you can choose to return only GPU(or CPU) devices.\n",
        "\n",
        "<pyopencl.Device 'HD Graphics 4000' on 'Apple' at 0x1024400>\n",
        "\n",
        "<pyopencl.Device 'Intel(R) Core(TM) i5-3210M CPU @ 2.50GHz' on 'Apple' at 0xffffffff>\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"A pyopencl.Device instance has following properties:\"\n",
      "print \n",
      "gpu = gpu_devices[0]\n",
      "cpu = cpu_devices[0]\n",
      "\n",
      "print \".address_bits: Unsigned integer with the size of the device's address space.\"\n",
      "print \"    GPU:\", gpu.address_bits\n",
      "print \"    CPU:\", cpu.address_bits\n",
      "print\n",
      "\n",
      "print \".extensions: String with the list of extensions supported by the device.\"\n",
      "print \"    GPU:\", gpu.extensions\n",
      "print \"    CPU:\", cpu.extensions\n",
      "print\n",
      "\n",
      "print \".global_mem_size: An unsigned long with the size of the device's global memory.\"\n",
      "print \"    GPU:\", gpu.global_mem_size\n",
      "print \"    CPU:\", cpu.global_mem_size\n",
      "\n",
      "\n",
      "print \".max_work_group_size: An unsigned integer with the maximum size of a workgroup for the device\"\n",
      "print \"    GPU:\", gpu.max_work_group_size\n",
      "print \"    CPU:\", cpu.max_work_group_size\n",
      "print\n",
      "\n",
      "print \".name: A string with the device's name.\"\n",
      "print \"    GPU:\", gpu.name\n",
      "print \"    CPU:\", cpu.name\n",
      "print\n",
      "\n",
      "print \".vedor:  Device's vendor name.\"\n",
      "print \"    GPU:\", gpu.vendor\n",
      "print \"    CPU:\", cpu.vendor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A pyopencl.Device instance has following properties:\n",
        "\n",
        ".address_bits: Unsigned integer with the size of the device's address space.\n",
        "    GPU: 64\n",
        "    CPU: 64\n",
        "\n",
        ".extensions: String with the list of extensions supported by the device.\n",
        "    GPU: cl_APPLE_SetMemObjectDestructor cl_APPLE_ContextLoggingFunctions cl_APPLE_clut cl_APPLE_query_kernel_names cl_APPLE_gl_sharing cl_khr_gl_event cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_image2d_from_buffer cl_khr_gl_depth_images cl_khr_depth_images \n",
        "    CPU: cl_APPLE_SetMemObjectDestructor cl_APPLE_ContextLoggingFunctions cl_APPLE_clut cl_APPLE_query_kernel_names cl_APPLE_gl_sharing cl_khr_gl_event cl_khr_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_image2d_from_buffer cl_APPLE_fp64_basic_ops cl_APPLE_fixed_alpha_channel_orders cl_APPLE_biased_fixed_point_image_formats cl_APPLE_command_queue_priority\n",
        "\n",
        ".global_mem_size: An unsigned long with the size of the device's global memory.\n",
        "    GPU: 1073741824\n",
        "    CPU: 8589934592\n",
        ".max_work_group_size: An unsigned integer with the maximum size of a workgroup for the device\n",
        "    GPU: 512\n",
        "    CPU: 1024\n",
        "\n",
        ".name: A string with the device's name.\n",
        "    GPU: HD Graphics 4000\n",
        "    CPU: Intel(R) Core(TM) i5-3210M CPU @ 2.50GHz\n",
        "\n",
        ".vedor:  Device's vendor name.\n",
        "    GPU: Intel\n",
        "    CPU: Intel\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "General Steps to Build and Deploy a Kernel\n",
      "===\n",
      "http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614 <br>\n",
      "http://www.drdobbs.com/open-source/build-and-deploy-opencl-kernels-in-pytho/240162981\n",
      "`    `\n",
      "<font size=\"3\">\n",
      "1. Obtain an OpenCL platform.<br>\n",
      "2. Obtain a device id for at least one device (accelerator).<br>\n",
      "3. Create a context for the selected device or devices.<br>\n",
      "4. Create the accelerator program from source code.<br>\n",
      "5. Build the program.<br>\n",
      "6. Create one or more kernels from the program functions.<br>\n",
      "7. Create a command queue for the target device.<br>\n",
      "8. Allocate device memory and move input data from the host to the device memory.<br>\n",
      "9. Associate the arguments to the kernel with kernel object.<br>\n",
      "10. Deploy the kernel for device execution.<br>\n",
      "11. Move the kernel's output data to host memory.<br>\n",
      "12. Release context, program, kernels and memory.<br>\n",
      "</font>\n",
      "`  `"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as cl\n",
      "from pyopencl import array\n",
      "import numpy\n",
      " \n",
      "if __name__ == \"__main__\":\n",
      "    vector = numpy.zeros((1, 1), cl.array.vec.float4)\n",
      "    matrix = numpy.zeros((1, 4), cl.array.vec.float4)\n",
      "    matrix[0, 0] = (1, 2, 4, 8)\n",
      "    matrix[0, 1] = (16, 32, 64, 128)\n",
      "    matrix[0, 2] = (3, 6, 9, 12)\n",
      "    matrix[0, 3] = (5, 10, 15, 25)\n",
      "    vector[0, 0] = (1, 2, 4, 8)\n",
      "     \n",
      "    ## Step #1. Obtain an OpenCL platform.\n",
      "    platform = cl.get_platforms()[0]\n",
      "     \n",
      "    ## It would be necessary to add some code to check the check the support for\n",
      "    ## the necessary platform extensions with platform.extensions\n",
      "     \n",
      "    ## Step #2. Obtain a device id for at least one device (accelerator).\n",
      "    device = platform.get_devices()[0]\n",
      "     \n",
      "    ## It would be necessary to add some code to check the check the support for\n",
      "    ## the necessary device extensions with device.extensions\n",
      "     \n",
      "    ## Step #3. Create a context for the selected device.\n",
      "    context = cl.Context([device])\n",
      "     \n",
      "    ## Step #4. Create the accelerator program from source code.\n",
      "    ## Step #5. Build the program.\n",
      "    ## Step #6. Create one or more kernels from the program functions.\n",
      "    program = cl.Program(context, \"\"\"\n",
      "        __kernel void matrix_dot_vector(__global const float4 *matrix,\n",
      "        __global const float4 *vector, __global float *result)\n",
      "        {\n",
      "          int gid = get_global_id(0);\n",
      "          result[gid] = dot(matrix[gid], vector[0]);\n",
      "        }\n",
      "        \"\"\").build()\n",
      "     \n",
      "    ## Step #7. Create a command queue for the target device.\n",
      "    queue = cl.CommandQueue(context)\n",
      "     \n",
      "    ## Step #8. Allocate device memory and move input data from the host to the device memory.\n",
      "    mem_flags = cl.mem_flags\n",
      "    matrix_buf = cl.Buffer(context, mem_flags.READ_ONLY | mem_flags.COPY_HOST_PTR, hostbuf=matrix)\n",
      "    vector_buf = cl.Buffer(context, mem_flags.READ_ONLY | mem_flags.COPY_HOST_PTR, hostbuf=vector)\n",
      "    matrix_dot_vector = numpy.zeros(4, numpy.float32)\n",
      "    destination_buf = cl.Buffer(context, mem_flags.WRITE_ONLY, matrix_dot_vector.nbytes)\n",
      "    ## Step #9. Associate the arguments to the kernel with kernel object.\n",
      "    ## Step #10. Deploy the kernel for device execution.\n",
      "    print matrix_dot_vector.shape\n",
      "    program.matrix_dot_vector(queue, matrix_dot_vector.shape, None, matrix_buf, vector_buf, destination_buf)\n",
      "     \n",
      "    ## Step #11. Move the kernel\u2019s output data to host memory.\n",
      "    cl.enqueue_copy(queue, matrix_dot_vector, destination_buf)\n",
      "     \n",
      "    ## Step #12. Release context, program, kernels and memory.\n",
      "    ## PyOpenCL performs this step for you, and therefore,\n",
      "    ## you don't need to worry about cleanup code\n",
      "     \n",
      "    print(matrix_dot_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-50-4677e38d5dc6>, line 50)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-4677e38d5dc6>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    program.matrix_dot_vector?\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cl.mem_flags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pyopencl._cl.mem_flags'>\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "program.matrix_dot_vector?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}